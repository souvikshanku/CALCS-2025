{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd9b481-8295-4762-b807-5cf076b010cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import dill\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification, AutoModel, GPT2Tokenizer\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# from dataset import TextDataset, clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75a417b-3bed-40c7-9087-bceaaf6ab233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_og = pd.read_parquet(\"cspref/data/train-00000-of-00001.parquet\")\n",
    "\n",
    "# little bit of cleaning\n",
    "for col in ['sent_1', 'sent_2']:\n",
    "    df_og[col] = df_og[col].apply(lambda x:  x.split('\\n')[0] if '\\n' in x else x)\n",
    "\n",
    "df = df_og.sample(n=int(df_og.shape[0] * 0.6), random_state=42)\n",
    "\n",
    "chosen_class = {\n",
    "    \"sent_1\": 0,\n",
    "    \"sent_2\": 1,\n",
    "    \"tie\": 2\n",
    "}\n",
    "\n",
    "df[\"chosen\"] = df[\"chosen\"].apply(lambda x: chosen_class[x])\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenized_data = []\n",
    "        self.label_dict = {\n",
    "            0: torch.tensor([1, 0, 0]),\n",
    "            1: torch.tensor([0, 1, 0]),\n",
    "            2: torch.tensor([0, 0, 1])\n",
    "        }\n",
    "\n",
    "        kwargs = {\n",
    "            # \"add_special_tokens\": True,\n",
    "            \"padding\": \"max_length\",\n",
    "            \"truncation\": True,\n",
    "            \"return_attention_mask\": True,\n",
    "            \"return_tensors\": \"pt\"\n",
    "        }\n",
    "\n",
    "        for idx in range(len(df)):\n",
    "            prepend = (\n",
    "                df.iloc[idx][\"original_l1\"]\n",
    "                + \"+\"\n",
    "                + df.iloc[idx][\"original_l2\"]\n",
    "                + \"->\"\n",
    "            )\n",
    "            text1 = prepend + df.iloc[idx][\"sent_1\"]\n",
    "            text2 = prepend + df.iloc[idx][\"sent_2\"]\n",
    "            text1_enc = self.tokenizer.encode_plus(text1, **kwargs)\n",
    "            text2_enc = self.tokenizer.encode_plus(text2, **kwargs)\n",
    "\n",
    "            chosen = df.iloc[idx][\"chosen\"]\n",
    "            label = self.label_dict[chosen]\n",
    "\n",
    "            self.tokenized_data.append((text1_enc, text2_enc, chosen, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.tokenized_data[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d2ff0a-b2d8-40e9-8859-6c7ee69a4313",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3db4a29-4914-4d8d-93b1-0d034d5b3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "batch_size = 8\n",
    "train_dataset = TextDataset(train_df, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77ead59-c29b-4bf9-be16-e7d8e1d5620a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecisionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecisionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(768, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.reward_to_class = nn.Linear(2, 3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        r1 = self.fc2(F.gelu(self.fc1(x1)))\n",
    "        r2 = self.fc2(F.gelu(self.fc1(x2)))\n",
    "        \n",
    "        out = F.relu(torch.concat((r1, r2), dim=1))\n",
    "        out = self.reward_to_class(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, enc_model, decision, device):\n",
    "        super(RewardModel, self).__init__()\n",
    "        self.enc_model = enc_model\n",
    "        self.decision = decision\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [x1, x2, label]\n",
    "        input_ids = x[0]['input_ids'].squeeze(dim=1).to(self.device)\n",
    "        attention_mask = x[0]['attention_mask'].squeeze(dim=1).to(self.device)\n",
    "        out1 = self.enc_model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        out1 = out1.hidden_states[-1][:, -1, :]\n",
    "\n",
    "        input_ids = x[1]['input_ids'].squeeze(dim=1).to(self.device)\n",
    "        attention_mask = x[1]['attention_mask'].squeeze(dim=1).to(self.device)\n",
    "        out2 = self.enc_model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        out2 = out2.hidden_states[-1][:, -1, :]\n",
    "\n",
    "        output = self.decision(out1, out2)\n",
    "        label = x[-1].to(self.device)\n",
    "\n",
    "        return output, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44286052-bc54-4d11-89fa-f59fadc2fc5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not anymore\n"
     ]
    }
   ],
   "source": [
    "MODEL = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "enc_model = AutoModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "dm = DecisionModel()\n",
    "rm = RewardModel(enc_model, dm, device)\n",
    "rm.to(device)\n",
    "\n",
    "print(\"Not anymore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af46b0ea-07bc-4dda-a3a6-223391ed5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": rm.decision.parameters(), \"lr\": 3e-5},\n",
    "    {\"params\": rm.enc_model.parameters(), \"lr\": 3e-5},\n",
    "], lr=3e-5)\n",
    "\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ccf354-f35c-4f25-8f25-42b7c0149256",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint_path = \"ckpts_nl/checkpoint_gpt2_60_3.pth\"\n",
    "# checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# rm.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "# print(scheduler.get_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c095286a-1c25-4504-8340-4bf78028c782",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8508423566818237\n",
      "0.9418230652809143\n",
      "0.9931835532188416\n",
      "0.785681962966919\n",
      "0.9073892831802368\n",
      "0.9551669955253601\n",
      "0.7368096113204956\n",
      "1.0029284954071045\n",
      "0.6765177249908447\n"
     ]
    }
   ],
   "source": [
    "completed_num_epochs = 6\n",
    "\n",
    "checkpoint_path = f\"ckpts_nl/checkpoint_gpt2_60_{completed_num_epochs - 1}.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "rm.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "\n",
    "epochs = 8 - completed_num_epochs\n",
    "\n",
    "\n",
    "accumulation_steps = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    rm.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_id, batch in enumerate(train_dataloader):\n",
    "        out, label = rm(batch)\n",
    "        loss = - (out * label).sum() / label.shape[0]\n",
    "        loss.backward()\n",
    "\n",
    "        if (batch_id + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_id % 100 == 0:\n",
    "            print(loss.item())\n",
    "\n",
    "    # If the number of batches isn't divisible by accumulation_steps,\n",
    "    # do one final step after the loop ends\n",
    "    if (batch_id + 1) % accumulation_steps != 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch + completed_num_epochs}\")\n",
    "    print(f\"Average Training Loss: {avg_loss:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    checkpoint = {\n",
    "        'model_state_dict': rm.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'epoch': epoch + completed_num_epochs,\n",
    "        'avg_loss': avg_loss\n",
    "    }\n",
    "\n",
    "    torch.save(checkpoint, f\"ckpts_nl/checkpoint_gpt2_60_{epoch + completed_num_epochs}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee05783-885f-45d8-af24-a67884f500f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(rm.state_dict(), \"gpt2_rm_dict_2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f7057-443f-45e4-862e-324aaea28d13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "785445c3-6619-4921-ae7e-5f4ea1a04248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"gpt2_rm_3_dict.pth\": 30%, epoch: 3\n",
    "# \"gpt2_rm_dict.pth\": 20%, epoch: 5\n",
    "\n",
    "rm.load_state_dict(torch.load(\"models_w_tie/gpt2_rm_w_tie_40_3.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa5e8707-716e-473d-81d7-fb51e523984a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5009, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "test_dataset = TextDataset(test_df, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "test_dataloader.dataset.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e69e6b-7113-4315-b3ff-825a9207f7cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm.load_state_dict(torch.load(\"models_w_tie/gpt2_rm_w_tie_40_3.pth\"))\n",
    "\n",
    "rm.eval()\n",
    "\n",
    "all_preds = []\n",
    "true_labels = []  # with randomized ties\n",
    "chosen = []\n",
    "pred_model_probs = []\n",
    "\n",
    "for batch_id, batch in enumerate(test_dataloader):\n",
    "    chosen += batch[2].tolist()\n",
    "    out, label = rm(batch)\n",
    "    probs = F.softmax(out, dim=1)\n",
    "    pred_model_probs += probs.to(\"cpu\").tolist()\n",
    "    all_preds += probs.argmax(dim=1)\n",
    "    true_labels += label.argmax(dim=1).to(\"cpu\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dfe86b9-218b-4241-9fca-4939336f7bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5983)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(all_preds) == torch.tensor(true_labels)).sum() / len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8de8339-bada-41b8-bf2f-74b166964983",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5670)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.load_state_dict(torch.load(\"models_w_tie/gpt2_rm_w_tie_40_2.pth\"))\n",
    "\n",
    "rm.eval()\n",
    "\n",
    "all_preds = []\n",
    "true_labels = []  # with randomized ties\n",
    "chosen = []\n",
    "pred_model_probs = []\n",
    "\n",
    "for batch_id, batch in enumerate(test_dataloader):\n",
    "    chosen += batch[2].tolist()\n",
    "    out, label = rm(batch)\n",
    "    probs = F.softmax(out, dim=1)\n",
    "    pred_model_probs += probs.to(\"cpu\").tolist()\n",
    "    all_preds += probs.argmax(dim=1)\n",
    "    true_labels += label.argmax(dim=1).to(\"cpu\").tolist()\n",
    "    \n",
    "(torch.tensor(all_preds) == torch.tensor(true_labels)).sum() / len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99c3dc72-91a7-4da7-a85b-81e21cc5b499",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7519)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(all_preds) == torch.tensor(true_labels)).sum() / len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3528baba-6619-47e8-b4aa-543e5565ae78",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# acuracy of non-tie\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m non_tie_preds \u001b[38;5;241m=\u001b[39m [(i, j, k) \u001b[38;5;28;01mfor\u001b[39;00m (i, j, k) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mall_preds\u001b[49m, true_labels, chosen) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mlen\u001b[39m([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (i, j, _) \u001b[38;5;129;01min\u001b[39;00m non_tie_preds \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m j]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(non_tie_preds)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_preds' is not defined"
     ]
    }
   ],
   "source": [
    "# acuracy of non-tie\n",
    "non_tie_preds = [(i, j, k) for (i, j, k) in zip(all_preds, true_labels, chosen) if k != 2]\n",
    "len([1 for (i, j, _) in non_tie_preds if i == j]) / len(non_tie_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30aa3c64-1998-4e9c-9b76-840b34a650f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGzCAYAAAAfeAwWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmWUlEQVR4nO3de3CU1f3H8U8IZAOSiyGQkBLCVVAgWqNivIESblIEoSNoq8FBvEx0BqKiqVaN1klEBrA2otMi6NRICyNYb6BgE6oGLxHkIlKJoUIlsWKTDUEWJOf3x2/YuiRh2c1uzu7m/ZrZ0X2ek32+J0/2yyfP7p5EGWOMAAAALOpkuwAAAAACCQAAsI5AAgAArCOQAAAA6wgkAADAOgIJAACwjkACAACsI5AAAADrCCQAAMA6Agm86tevn2bNmmW7DABhht4BXxBI4PbBBx/okUceUV1dXbsdc/fu3Zo3b54uueQSxcbGKioqSnv37m234wNoOxu945VXXtGMGTM0YMAAdevWTUOGDNHdd9/drjUgsKL4WzY4YeHChbr33ntVXV2tfv36ube7XC516tRJXbp0CfgxV6xYodmzZ+ucc85R586dtXXr1mbHBxDabPSO5ORkpaWlaerUqerbt6+2b9+uZ599VgMGDNCnn36qrl27BvyYCK7OtgtA6HM4HEF77GuuuUZ1dXWKi4vTwoULtXXr1qAdC0D7CmbvWL16tUaPHu2xLSsrS7m5uXrppZd0yy23BO3YCA5esoEk6ZFHHtG9994rSerfv7+ioqLcL5+09DpwXV2d5s6dq/T0dDkcDg0aNEhPPPGEmpqafDpuUlKS4uLiAjUNAO3MVu84OYxI0rXXXitJ2rVrl19zgV1cIYEkadq0afrnP/+pl19+WYsXL1ZycrIkqWfPns3GHj58WKNGjdK///1v3Xbbberbt68++OADFRQU6MCBA1qyZEk7Vw/AllDqHTU1NZLkrgHhhUACSVJmZqbOP/98vfzyy5o6deop38OxaNEiVVVVacuWLRo8eLAk6bbbblNaWpqefPJJ3X333UpPT2+nygHYFEq944knnlB0dLR++ctf+v0YsIeXbOCzVatW6fLLL9eZZ56p7777zn3LycnR8ePHtWnTJtslAghBwewdpaWlWrZsme6++2532EF44QoJfPbll19q27ZtLV6SlaRvv/22nSsCEA6C1Tv+8Y9/aPbs2Ro/frwef/zxtpQIiwgk8FlTU5PGjh2r+fPnt7j/rLPOaueKAISDYPSOzz77TNdcc42GDx+u1atXq3Nn/lkLV5w5uEVFRZ3WuIEDB+rQoUPKyckJckUAwoGt3lFVVaUJEyaoV69eevPNN9W9e/eAPC7s4D0kcDvjjDMkyetKh9ddd50qKiq0fv36Zvvq6ur0448/BqM8ACHKRu+oqanRuHHj1KlTJ61fv77Vl4EQPrhCAresrCxJ0gMPPKCZM2eqS5cumjx5crNx9957r/72t7/pF7/4hWbNmqWsrCw1NjZq+/btWr16tfbu3XvaH7urr6/X008/LUl6//33JUl/+MMflJiYqMTERN15550Bmh2AYLHROyZMmKCvvvpK8+fP13vvvaf33nvPvS8lJUVjx44NzOTQfgzwE4899pj52c9+Zjp16mQkmerqapORkWFyc3M9xjU0NJiCggIzaNAgExMTY5KTk80ll1xiFi5caI4ePXrax6uurjaSWrxlZGQEdnIAgqa9e0drfUOSGTVqVGAnh3bB37IBAADW8R4SAABgHe8hQVB8//33Onr0aKv7o6OjeRMagGboHR0XL9kgKEaPHq3y8vJW92dkZGjv3r3tVxCAsEDv6LgIJAiKyspK/fe//211f9euXXXppZe2Y0UAwgG9o+MikAAAAOt4UysAALAu5N7U2tTUpG+++UZxcXGnvRwxgMAyxqihoUFpaWnq1Ck8fm+hdwB2tbVvhFwg+eabb5Senm67DACS9u3bpz59+tgu47TQO4DQ4G/fCLlAEhcXJ+n/JxQfH2+5GqBjcjqdSk9Pdz8fwwG9A7CrrX0j5ALJiUut8fHxNBXAsnB66YPeAYQGf/tGeLw4DAAAIhqBBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABYRyABAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB2BBAAAWNfZdgHoGPrd/4bH/b3FkyxVAsCWk/uARC/A/3CFBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABYRyABAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB2BBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABYRyABAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHU+BZKlS5cqMzNT8fHxio+PV3Z2tt566y33/tGjRysqKsrjdvvttwe8aADhhd4BwJvOvgzu06ePiouLNXjwYBlj9MILL2jKlCnasmWLhg0bJkmaM2eOHn30UffXdOvWLbAVAwg79A4A3vgUSCZPnuxx//HHH9fSpUu1efNmd1Pp1q2bUlNTA1chgLBH7wDgjd/vITl+/LhWrlypxsZGZWdnu7e/9NJLSk5O1vDhw1VQUKDDhw+f8nFcLpecTqfHDUDkoncAaIlPV0gkafv27crOztaRI0fUvXt3rVmzRuecc44k6YYbblBGRobS0tK0bds23Xfffdq9e7deeeWVVh+vqKhIhYWF/s8AIanf/W/YLgEhht6BlpzcK/YWT7JUCWyLMsYYX77g6NGj+vrrr1VfX6/Vq1frT3/6k8rLy92N5afeffddjRkzRnv27NHAgQNbfDyXyyWXy+W+73Q6lZ6ervr6esXHx/s4HYQKb4GEphPanE6nEhISAvo8pHfgdH5RoTeEr7b2DZ+vkMTExGjQoEGSpKysLH388cd66qmn9NxzzzUbO3LkSEk6ZVNxOBxyOBy+lgEgzNA7AJxKm9chaWpq8vgt5ae2bt0qSerdu3dbDwMgwtA7APyUT1dICgoKNHHiRPXt21cNDQ0qLS1VWVmZ1q9fr6qqKpWWlurqq69Wjx49tG3bNs2bN09XXHGFMjMzg1U/gDBA7wDgjU+B5Ntvv9VNN92kAwcOKCEhQZmZmVq/fr3Gjh2rffv2acOGDVqyZIkaGxuVnp6u6dOn68EHHwxW7QDCBL0DgDc+BZJly5a1ui89PV3l5eVtLghA5KF3APCGv2UDAACsI5AAAADrCCQAAMA6AgkAALCOQAIAAKwjkAAAAOsIJAAAwDoCCQAAsI5AAgAArCOQAAAA6wgkAADAOgIJAACwzqc/rgcESr/73/C4v7d4UoesAQgm2z/jJx8fOBWukAAAAOsIJAAAwDoCCQAAsI5AAgAArCOQAAAA6wgkAADAOgIJAACwjkACAACsY2E0hATbCzgBaDsWQkNbcIUEAABYRyABAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB0Lo8EvLIAEIBi89RYWTYxcXCEBAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANb5FEiWLl2qzMxMxcfHKz4+XtnZ2Xrrrbfc+48cOaK8vDz16NFD3bt31/Tp01VbWxvwogGEF3oHAG98CiR9+vRRcXGxKisr9cknn+iqq67SlClTtHPnTknSvHnz9Nprr2nVqlUqLy/XN998o2nTpgWlcADhg94BwBuf1iGZPHmyx/3HH39cS5cu1ebNm9WnTx8tW7ZMpaWluuqqqyRJy5cv19lnn63Nmzfr4osvbvExXS6XXC6X+77T6fR1DgBCHL0DgDd+L4x2/PhxrVq1So2NjcrOzlZlZaWOHTumnJwc95ihQ4eqb9++qqioaLWpFBUVqbCw0N8yEKFaWhyJBZEiA70jcrBAIgLJ5ze1bt++Xd27d5fD4dDtt9+uNWvW6JxzzlFNTY1iYmKUmJjoMT4lJUU1NTWtPl5BQYHq6+vdt3379vk8CQChj94B4FR8vkIyZMgQbd26VfX19Vq9erVyc3NVXl7udwEOh0MOh8PvrwcQHugdAE7F50ASExOjQYMGSZKysrL08ccf66mnntKMGTN09OhR1dXVefymU1tbq9TU1IAVDCA80TsAnEqb1yFpamqSy+VSVlaWunTpoo0bN7r37d69W19//bWys7PbehgAEYbeAeCnfLpCUlBQoIkTJ6pv375qaGhQaWmpysrKtH79eiUkJGj27NnKz89XUlKS4uPjdddddyk7O7vVN6UB6BjoHQC88SmQfPvtt7rpppt04MABJSQkKDMzU+vXr9fYsWMlSYsXL1anTp00ffp0uVwujR8/Xs8880xQCgcQPugdALzxKZAsW7bslPtjY2NVUlKikpKSNhUFILLQOwB4w9+yAQAA1hFIAACAdX6v1Aq0t5NXhWTlVqB9sTIrgokrJAAAwDoCCQAAsI5AAgAArCOQAAAA6wgkAADAOgIJAACwjkACAACsI5AAAADrWBgtBITDgl8siAQgFIRjvwzFGkMRV0gAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB2BBAAAWEcgAQAA1rEwWhhoj0V2WMgHQCSgX4YvrpAAAADrCCQAAMA6AgkAALCOQAIAAKwjkAAAAOsIJAAAwDoCCQAAsI5AAgAArCOQAAAA6wgkAADAOgIJAACwjkACAACsI5AAAADrCCQAAMA6nwJJUVGRLrzwQsXFxalXr16aOnWqdu/e7TFm9OjRioqK8rjdfvvtAS0aQHihdwDwxqdAUl5erry8PG3evFnvvPOOjh07pnHjxqmxsdFj3Jw5c3TgwAH3bcGCBQEtGkB4oXcA8KazL4PXrVvncX/FihXq1auXKisrdcUVV7i3d+vWTampqYGpEEDYo3cA8KZN7yGpr6+XJCUlJXlsf+mll5ScnKzhw4eroKBAhw8fbvUxXC6XnE6nxw1AZKN3ADiZT1dIfqqpqUlz587VpZdequHDh7u333DDDcrIyFBaWpq2bdum++67T7t379Yrr7zS4uMUFRWpsLDQ3zLgh373vxGQMaHm5Jr3Fk+yVAlOhd4RusLxOeStV4XjnDoqvwNJXl6eduzYoffee89j+6233ur+/xEjRqh3794aM2aMqqqqNHDgwGaPU1BQoPz8fPd9p9Op9PR0f8sCEOLoHQBa4lcgufPOO/X6669r06ZN6tOnzynHjhw5UpK0Z8+eFpuKw+GQw+HwpwwAYYbeAaA1PgUSY4zuuusurVmzRmVlZerfv7/Xr9m6daskqXfv3n4VCCD80TsAeONTIMnLy1NpaaleffVVxcXFqaamRpKUkJCgrl27qqqqSqWlpbr66qvVo0cPbdu2TfPmzdMVV1yhzMzMoEwAQOijdwDwxqdAsnTpUkn/v4DRTy1fvlyzZs1STEyMNmzYoCVLlqixsVHp6emaPn26HnzwwYAVDCD80DsAeOPzSzankp6ervLy8jYVBCDy0DsAeMPfsgEAANYRSAAAgHV+r0OC8BGOi5wFgq8LIrGAEsKZP8/zjtgbeJ6HLq6QAAAA6wgkAADAOgIJAACwjkACAACsI5AAAADrCCQAAMA6AgkAALCOQAIAAKxjYTSgFe2xgBKLNEWuYJ/bjrioGSIbV0gAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB2BBAAAWEcgAQAA1rEwGsKWrwtDsZAUOjqeMwhlXCEBAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB2BBAAAWEcgAQAA1rFSawRidcXgOPn7urd4kqVK0BHxvA4OntehgyskAADAOgIJAACwjkACAACsI5AAAADrfAokRUVFuvDCCxUXF6devXpp6tSp2r17t8eYI0eOKC8vTz169FD37t01ffp01dbWBrRoAOGF3gHAG58CSXl5ufLy8rR582a98847OnbsmMaNG6fGxkb3mHnz5um1117TqlWrVF5erm+++UbTpk0LeOEAwge9A4A3Pn3sd926dR73V6xYoV69eqmyslJXXHGF6uvrtWzZMpWWluqqq66SJC1fvlxnn322Nm/erIsvvjhwlQMIG/QOAN606T0k9fX1kqSkpCRJUmVlpY4dO6acnBz3mKFDh6pv376qqKho8TFcLpecTqfHDUBko3cAOJnfC6M1NTVp7ty5uvTSSzV8+HBJUk1NjWJiYpSYmOgxNiUlRTU1NS0+TlFRkQoLC/0to0NiIR+EM3oHwg2L0rUPv6+Q5OXlaceOHVq5cmWbCigoKFB9fb37tm/fvjY9HoDQRu8A0BK/rpDceeedev3117Vp0yb16dPHvT01NVVHjx5VXV2dx286tbW1Sk1NbfGxHA6HHA6HP2UACDP0DgCt8ekKiTFGd955p9asWaN3331X/fv399iflZWlLl26aOPGje5tu3fv1tdff63s7OzAVAwg7NA7AHjj0xWSvLw8lZaW6tVXX1VcXJz7td2EhAR17dpVCQkJmj17tvLz85WUlKT4+Hjdddddys7O5l3yQAdG7wDgjU+BZOnSpZKk0aNHe2xfvny5Zs2aJUlavHixOnXqpOnTp8vlcmn8+PF65plnAlIsgPBE7wDgjU+BxBjjdUxsbKxKSkpUUlLid1EAIgu9A4A3/C0bAABgHYEEAABY5/fCaGjZ6Sygw0JmANBxeft3oqP+G8EVEgAAYB2BBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABYRyABAADWEUgAAIB1BBIAAGAdK7We5OQV9DrqinnwrqXVFkPt5yUcarQhHJ7np7PqM3BCOPxMe8MVEgAAYB2BBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABYRyABAADWEUgAAIB1LIzmRTAWmwn0gkcsoAQAgRGMfkrPPz1cIQEAANYRSAAAgHUEEgAAYB2BBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABYx8JobRSpC9TAP95+HgKxsB4iA70DrQnGgpzhgCskAADAOgIJAACwjkACAACsI5AAAADrfA4kmzZt0uTJk5WWlqaoqCitXbvWY/+sWbMUFRXlcZswYUKg6gUQhugbALzxOZA0Njbq3HPPVUlJSatjJkyYoAMHDrhvL7/8cpuKBBDe6BsAvPH5Y78TJ07UxIkTTznG4XAoNTXV76IARBb6BgBvgvIekrKyMvXq1UtDhgzRHXfcoYMHD7Y61uVyyel0etwAdDy+9A2J3gFEmoAvjDZhwgRNmzZN/fv3V1VVlX7zm99o4sSJqqioUHR0dLPxRUVFKiwsDHQZQdMeixmxYBI6Gl/7hhR+vQORK9g9u6P8mxDwQDJz5kz3/48YMUKZmZkaOHCgysrKNGbMmGbjCwoKlJ+f777vdDqVnp4e6LIAhDBf+4ZE7wAiTdA/9jtgwAAlJydrz549Le53OByKj4/3uAHo2Lz1DYneAUSaoAeS/fv36+DBg+rdu3ewDwUgQtA3gI7H55dsDh065PFbS3V1tbZu3aqkpCQlJSWpsLBQ06dPV2pqqqqqqjR//nwNGjRI48ePD2jhAMIHfQOANz4Hkk8++URXXnml+/6J13Bzc3O1dOlSbdu2TS+88ILq6uqUlpamcePG6bHHHpPD4Qhc1QDCCn0DgDc+B5LRo0fLGNPq/vXr17epIACRh74BwBv+lg0AALCOQAIAAKwjkAAAAOsCvjAaAP+dvCLj3uJJliqBrzrKappAsHCFBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABYRyABAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB2BBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABY19l2AcHW7/43bJcAuPHz2HFx7tGefP1521s8KUiVnD6ukAAAAOsIJAAAwDoCCQAAsI5AAgAArCOQAAAA6wgkAADAOgIJAACwjkACAACsi/iF0YCOhMW3/HPy9y0UFokCOhqukAAAAOsIJAAAwDoCCQAAsI5AAgAArCOQAAAA63wOJJs2bdLkyZOVlpamqKgorV271mO/MUYPPfSQevfura5duyonJ0dffvlloOoFEIboGwC88TmQNDY26txzz1VJSUmL+xcsWKDf//73evbZZ/Xhhx/qjDPO0Pjx43XkyJE2FwsgPNE3AHjj8zokEydO1MSJE1vcZ4zRkiVL9OCDD2rKlCmSpBdffFEpKSlau3atZs6c2bZqAYQl+gYAbwL6HpLq6mrV1NQoJyfHvS0hIUEjR45URUVFi1/jcrnkdDo9bgA6Dn/6hkTvACJNQFdqrampkSSlpKR4bE9JSXHvO1lRUZEKCwv9PiYrLKIji4SVWf3pG1Lbe8ep0FfQ0dl4Dlj/lE1BQYHq6+vdt3379tkuCUAYoHcAkSWggSQ1NVWSVFtb67G9trbWve9kDodD8fHxHjcAHYc/fUOidwCRJqCBpH///kpNTdXGjRvd25xOpz788ENlZ2cH8lAAIgR9A4Dkx3tIDh06pD179rjvV1dXa+vWrUpKSlLfvn01d+5c/e53v9PgwYPVv39//fa3v1VaWpqmTp0ayLoBhBH6BgBvfA4kn3zyia688kr3/fz8fElSbm6uVqxYofnz56uxsVG33nqr6urqdNlll2ndunWKjY0NXNUAwgp9A4A3PgeS0aNHyxjT6v6oqCg9+uijevTRR9tUGIDIQd8A4I31T9kAAAAQSAAAgHUBXRgtFETCQlHACSzQFbroNYgkofDzzBUSAABgHYEEAABYRyABAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHURtzAaEMlCYfGijojvOxB8XCEBAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB2BBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABYRyABAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB2BBAAAWEcgAQAA1hFIAACAdQQSAABgXcADySOPPKKoqCiP29ChQwN9GAARhL4BoHMwHnTYsGHasGHD/w7SOSiHARBB6BtAxxaUZ3znzp2VmpoajIcGEKHoG0DHFpT3kHz55ZdKS0vTgAED9Ktf/Upff/11q2NdLpecTqfHDUDH40vfkOgdQKQJeCAZOXKkVqxYoXXr1mnp0qWqrq7W5ZdfroaGhhbHFxUVKSEhwX1LT08PdEkAQpyvfUOidwCRJsoYY4J5gLq6OmVkZGjRokWaPXt2s/0ul0sul8t93+l0Kj09XfX19YqPj/f6+P3ufyOg9QKRbm/xJK9jnE6nEhISTvt5GGje+obUtt5B3wB80x59I+jvGktMTNRZZ52lPXv2tLjf4XDI4XAEuwwAYcRb35DoHUCkCfo6JIcOHVJVVZV69+4d7EMBiBD0DaDjCXggueeee1ReXq69e/fqgw8+0LXXXqvo6Ghdf/31gT4UgAhB3wAQ8Jds9u/fr+uvv14HDx5Uz549ddlll2nz5s3q2bNnoA8FIELQNwAEPJCsXLky0A8JIMLRNwDwt2wAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB2BBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABYRyABAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB2BBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABYRyABAADWEUgAAIB1BBIAAGAdgQQAAFhHIAEAANYRSAAAgHUEEgAAYB2BBAAAWEcgAQAA1hFIAACAdQQSAABgHYEEAABYF7RAUlJSon79+ik2NlYjR47URx99FKxDAYgQ9A2g4wpKIPnLX/6i/Px8Pfzww/r000917rnnavz48fr222+DcTgAEYC+AXRsQQkkixYt0pw5c3TzzTfrnHPO0bPPPqtu3brp+eefD8bhAEQA+gbQsXUO9AMePXpUlZWVKigocG/r1KmTcnJyVFFR0Wy8y+WSy+Vy36+vr5ckOZ3O0zpek+twGysGOpbTeW6dGGOMCXY5knzvG1Lbegd9A/BNe/SNgAeS7777TsePH1dKSorH9pSUFH3xxRfNxhcVFamwsLDZ9vT09ECXBkBSwpLTH9vQ0KCEhISg1XKCr31DoncA7ak9+kbAA4mvCgoKlJ+f777f1NSk77//Xj169FBUVFSrX+d0OpWenq59+/YpPj6+PUoNqkiaTyTNReqY8zHGqKGhQWlpae1c3enzp3d0xHMZLiJpLlJkzed059LWvhHwQJKcnKzo6GjV1tZ6bK+trVVqamqz8Q6HQw6Hw2NbYmLiaR8vPj4+7E/2T0XSfCJpLlLHm097XBk5wde+IbWtd3S0cxlOImkuUmTN53Tm0pa+EfA3tcbExCgrK0sbN250b2tqatLGjRuVnZ0d6MMBiAD0DQBBeckmPz9fubm5uuCCC3TRRRdpyZIlamxs1M033xyMwwGIAPQNoGMLSiCZMWOG/vOf/+ihhx5STU2NzjvvPK1bt67ZG9bawuFw6OGHH252yTZcRdJ8ImkuEvNpL/QN30XSfCJpLlJkzae95hJl2utzfQAAAK3gb9kAAADrCCQAAMA6AgkAALCOQAIAAKwjkAAAAOtCKpCUlJSoX79+io2N1ciRI/XRRx+dcvyqVas0dOhQxcbGasSIEXrzzTc99htj9NBDD6l3797q2rWrcnJy9OWXXwZzCm6+zOWPf/yjLr/8cp155pk688wzlZOT02z8rFmzFBUV5XGbMGFCsKfh5st8VqxY0azW2NhYjzE2z43k23xGjx7dbD5RUVGaNGmSe4yt87Np0yZNnjxZaWlpioqK0tq1a71+TVlZmc4//3w5HA4NGjRIK1asaDbG1+eiTfQN+kZ7iJSeIYVw3zAhYuXKlSYmJsY8//zzZufOnWbOnDkmMTHR1NbWtjj+/fffN9HR0WbBggXm888/Nw8++KDp0qWL2b59u3tMcXGxSUhIMGvXrjWfffaZueaaa0z//v3NDz/8EFJzueGGG0xJSYnZsmWL2bVrl5k1a5ZJSEgw+/fvd4/Jzc01EyZMMAcOHHDfvv/++6DOw9/5LF++3MTHx3vUWlNT4zHG1rnxZz4HDx70mMuOHTtMdHS0Wb58uXuMrfPz5ptvmgceeMC88sorRpJZs2bNKcd/9dVXplu3biY/P998/vnn5umnnzbR0dFm3bp17jG+fn9som/QN0Lx3IRyzzAmdPtGyASSiy66yOTl5bnvHz9+3KSlpZmioqIWx1933XVm0qRJHttGjhxpbrvtNmOMMU1NTSY1NdU8+eST7v11dXXG4XCYl19+OQgz+B9f53KyH3/80cTFxZkXXnjBvS03N9dMmTIl0KWeFl/ns3z5cpOQkNDq49k8N8a0/fwsXrzYxMXFmUOHDrm32Tw/J5xOY5k/f74ZNmyYx7YZM2aY8ePHu++39fvTnugb/0PfCJ5I7RnGhFbfCImXbI4eParKykrl5OS4t3Xq1Ek5OTmqqKho8WsqKio8xkvS+PHj3eOrq6tVU1PjMSYhIUEjR45s9TEDwZ+5nOzw4cM6duyYkpKSPLaXlZWpV69eGjJkiO644w4dPHgwoLW3xN/5HDp0SBkZGUpPT9eUKVO0c+dO9z5b50YKzPlZtmyZZs6cqTPOOMNju43z4ytvz5tAfH/aC33DE30jODp6z5Dar2+ERCD57rvvdPz48WZLRKekpKimpqbFr6mpqTnl+BP/9eUxA8GfuZzsvvvuU1pamsfJnTBhgl588UVt3LhRTzzxhMrLyzVx4kQdP348oPWfzJ/5DBkyRM8//7xeffVV/fnPf1ZTU5MuueQS7d+/X5K9cyO1/fx89NFH2rFjh2655RaP7bbOj69ae944nU798MMPAfn5bS/0DU/0jeDo6D1Dar++EZS/ZQP/FRcXa+XKlSorK/N4Q9fMmTPd/z9ixAhlZmZq4MCBKisr05gxY2yU2qrs7GyPv9B6ySWX6Oyzz9Zzzz2nxx57zGJlbbds2TKNGDFCF110kcf2cDo/iDz0jdBFzzh9IXGFJDk5WdHR0aqtrfXYXltbq9TU1Ba/JjU19ZTjT/zXl8cMBH/mcsLChQtVXFyst99+W5mZmaccO2DAACUnJ2vPnj1trvlU2jKfE7p06aKf//zn7lptnRupbfNpbGzUypUrNXv2bK/Haa/z46vWnjfx8fHq2rVrQM53e6Fv/D/6Ruiem0joGVL79Y2QCCQxMTHKysrSxo0b3duampq0ceNGj8T8U9nZ2R7jJemdd95xj+/fv79SU1M9xjidTn344YetPmYg+DMXSVqwYIEee+wxrVu3ThdccIHX4+zfv18HDx5U7969A1J3a/ydz08dP35c27dvd9dq69xIbZvPqlWr5HK59Otf/9rrcdrr/PjK2/MmEOe7vdA36BuhfG6kyOgZUjv2jdN++2uQrVy50jgcDrNixQrz+eefm1tvvdUkJia6P/Z14403mvvvv989/v333zedO3c2CxcuNLt27TIPP/xwix/fS0xMNK+++qrZtm2bmTJlSrt9RMyXuRQXF5uYmBizevVqj4+ANTQ0GGOMaWhoMPfcc4+pqKgw1dXVZsOGDeb88883gwcPNkeOHAnqXPyZT2FhoVm/fr2pqqoylZWVZubMmSY2Ntbs3LnTY842zo0/8znhsssuMzNmzGi23eb5aWhoMFu2bDFbtmwxksyiRYvMli1bzL/+9S9jjDH333+/ufHGG93jT3x879577zW7du0yJSUlLX5871Tfn1BC36BvhOK5OSEUe8aJ44di3wiZQGKMMU8//bTp27eviYmJMRdddJHZvHmze9+oUaNMbm6ux/i//vWv5qyzzjIxMTFm2LBh5o033vDY39TUZH7729+alJQU43A4zJgxY8zu3bvbYyo+zSUjI8NIanZ7+OGHjTHGHD582IwbN8707NnTdOnSxWRkZJg5c+a06z8Qvsxn7ty57rEpKSnm6quvNp9++qnH49k8N8b4/rP2xRdfGEnm7bffbvZYNs/P3//+9xZ/dk7Un5uba0aNGtXsa8477zwTExNjBgwY4LE2wgmn+v6EGvoGfSPU5mJM6PYMY0K3b0QZY4xP124AAAACLCTeQwIAADo2AgkAALCOQAIAAKwjkAAAAOsIJAAAwDoCCQAAsI5AAgAArCOQAAAA6wgkAADAOgIJAACwjkACAACs+z/xh3BvpWblZwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tie_1 = [p[0] for p, c in zip(pred_model_probs, chosen) if c == 2]\n",
    "tie_2 = [p[1] for p, c in zip(pred_model_probs, chosen) if c == 2]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].hist(tie_1, bins=50)\n",
    "axs[0].set_title(\"tie_1\")\n",
    "\n",
    "axs[1].hist(tie_2, bins=50)\n",
    "axs[1].set_title(\"tie_2\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b044fc03-4fcb-4846-a12a-b6e1cc4e4684",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_1 = [p[0] for p, c in zip(pred_model_probs, chosen) if c == 0]\n",
    "class_2 = [p[1] for p, c in zip(pred_model_probs, chosen) if c == 1]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].hist(class_1, bins=50)\n",
    "axs[0].set_title(\"class_1\")\n",
    "\n",
    "axs[1].hist(class_2, bins=50)\n",
    "axs[1].set_title(\"class_2\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142056d2-2395-41b2-b12a-58299a9bc464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff375e4-42e6-4b77-8ff5-7065ebef2636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3dabd-dc7f-4636-95bd-b49ada6dcedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b83fa994-dc01-406c-a019-7a304a3e8158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 9)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    on=[\"original_l1\", \"original_l2\", \"sent_1\", \"sent_2\", \"chosen\"]\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39988ecc-cbc4-4635-a6c9-33af6a9224d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(out, dim=1).argmax(dim=1).to(\"cpu\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7b393478-8676-4b1f-9cfb-b8c84b50bb55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7306, -0.6571]], device='cuda:1', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b259d149-0b20-4d4e-8bf2-79c44efb3e16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1]], device='cuda:1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c9092-a705-436a-a19a-18cfd6c02b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff435b2c-11b4-4de7-8d3c-e8d5d8ff7e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35123f25-7114-428c-b210-3b3dc41b3960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b47637-407f-4db6-9b4a-abd20d1a2599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3bcc8f-f27f-4de1-af26-c0917ee4f952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da154cc-0098-4889-b0f6-dcf0e7b36dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d89cb8-8757-4ae2-bd75-b8ba27ef966c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2e31f-34ea-4020-8b95-197e282bfbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864863bf-88f7-440d-9554-ee7bb48279f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1d252-1662-4cac-9a1d-c12c8959afd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6b0df-04b0-4ecb-a0e8-afe68c376146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecee4935-ffde-4dae-9167-b2ce9d5bdcfd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 140] at entry 0 and [1, 165] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m      3\u001b[0m tout \u001b[38;5;241m=\u001b[39m rm(b)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 140] at entry 0 and [1, 165] at entry 1"
     ]
    }
   ],
   "source": [
    "for b in train_dataloader:\n",
    "    break\n",
    "tout = rm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c381a1cf-2ceb-4f1c-9f79-c6f70a3afaae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7010, -0.6854],\n",
       "         [-0.6841, -0.7022],\n",
       "         [-0.6704, -0.7164],\n",
       "         [-0.6816, -0.7048],\n",
       "         [-0.6888, -0.6975],\n",
       "         [-0.8291, -0.5735],\n",
       "         [-0.6787, -0.7078],\n",
       "         [-0.6922, -0.6941]], device='cuda:1', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[0, 1],\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         [1, 0]], device='cuda:1'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f22911-5bd9-4660-a882-e0107bdd4307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.6722, device='cuda:1', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tout[0] * tout[1]).sum() / tout[1].shape[0]\n",
    "(out * label).sum() / label.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "510a2f76-62da-4a27-bf32-db63429154e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tout[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea2b01-061f-4999-9a2e-e43aae7a39aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e506a3-d22a-4bbf-9bbf-0509c2d15ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbde52-aea9-4dee-8f85-a8c1fed26ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3edfd-077b-47ea-a0b0-d060d1ff1b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393bd0e-1269-48d4-b8eb-c83bf98f1be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1095535b-3bf5-431c-83a2-cfaa525145a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d45d942-d1a2-4e47-a132-94142b478a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_model = AutoModel.from_pretrained(\"gpt2\")\n",
    "enc_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f666db32-2ad3-46f0-8570-5057e32b29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"the meaning of life \"\n",
    "inp = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "out = enc_model(input_ids=inp[\"input_ids\"].to(device), attention_mask=inp[\"attention_mask\"].to(device), output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fd3d43e-9a9b-4b7e-a9a8-723361a2391c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d443d53-c41a-45ce-8137-0ea01c9a282e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1, out2 = out.hidden_states[-1][:, -1, :], out.hidden_states[-1][:, 0, :]\n",
    "\n",
    "out1.shape, out2.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1be45727-eda9-4238-a506-72134782b468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# F.softmax(\n",
    "r1 = nn.Linear(64, 1).to(device)(\n",
    "F.gelu(\n",
    "    nn.Linear(768, 64).to(device)(\n",
    "        torch.concat([out2, out1, out2, out2], dim=0)\n",
    "    )\n",
    ")\n",
    ")\n",
    "r2 = nn.Linear(64, 1).to(device)(\n",
    "F.gelu(\n",
    "    nn.Linear(768, 64).to(device)(\n",
    "        torch.concat([out1, out2, out2, out2], dim=0)\n",
    "    )\n",
    ")\n",
    ")\n",
    "# , dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "342e169b-59ca-46db-b063-23dacd9e5acf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0151],\n",
       "         [ 0.1738],\n",
       "         [-0.0151],\n",
       "         [-0.0151]], device='cuda:3', grad_fn=<AddmmBackward0>),\n",
       " tensor([[0.0393],\n",
       "         [0.0578],\n",
       "         [0.0578],\n",
       "         [0.0578]], device='cuda:3', grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cafdd22-26ee-4ee3-9a17-d0b2ded5a312",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0393],\n",
       "        [0.1738, 0.0578],\n",
       "        [0.0000, 0.0578],\n",
       "        [0.0000, 0.0578]], device='cuda:3', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.relu(torch.concat((r1, r2), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f66f7de-ba50-4f56-ba02-de022bcee5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5560,  0.7763,  0.2602],\n",
       "        [ 0.3082,  0.3112,  0.1111],\n",
       "        [ 0.1885,  0.2698, -0.0855],\n",
       "        [ 0.1885,  0.2698, -0.0855]], device='cuda:1',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = nn.Linear(2, 3).to(device)(\n",
    "    torch.concat((r1, r2), dim=1)\n",
    ")\n",
    "\n",
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65997000-2d50-4102-b409-fdf4ee9a9f01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3344, 0.4168, 0.2488],\n",
       "        [0.3541, 0.3552, 0.2908],\n",
       "        [0.3515, 0.3813, 0.2672],\n",
       "        [0.3515, 0.3813, 0.2672]], device='cuda:1', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(cl, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031712a-7e1b-4276-8088-1765f16fcfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecisionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(768, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.reward_to_class = nn.Linear(2, 3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        r1 = self.fc2(F.gelu(self.fc1(x1)))\n",
    "        r2 = self.fc2(F.gelu(self.fc1(x2)))\n",
    "\n",
    "        out = self.reward_to_class(\n",
    "            torch.concat((r1, r2), dim=1)\n",
    "        )\n",
    "\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec001af9-58c9-435e-bde4-3a578719ee70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8041, 0.1959],\n",
       "        [0.8815, 0.1185],\n",
       "        [0.7102, 0.2898],\n",
       "        [0.7102, 0.2898]], device='cuda:1', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.concat((r1, r2), dim=1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d00300ad-5a17-45ca-9a76-86c0e945320e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"hi there\"\n",
    "inp = tokenizer(prompt, return_tensors=\"pt\")\n",
    "out = enc_model.to(device)(input_ids=inp[\"input_ids\"].to(device), attention_mask=inp[\"attention_mask\"].to(device), output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "af455f17-f3fa-4813-83ea-82626f950e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d66ae2e0-e7da-47eb-8844-14e017802d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   11,   269,   264,  ..., 46136, 35061, 45384])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.shape\n",
    "out.logits[:, -1, :].sort(descending=True).indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "80303f3c-9f77-4167-a9a4-efd3c4baa793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      ".\n",
      ",\n",
      "was\n",
      "'s\n",
      "are\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(out.logits[:, -1, :].sort(descending=True).indices[0]):\n",
    "    print(tokenizer.convert_ids_to_tokens(j.item()))\n",
    "    # print(i, j)\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "855ac89e-6d5d-4ae0-8a3f-c5fe9fd002b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([50257]), torch.Size([1, 12, 25, 64])]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k[1][0][0].shape for k in out.items()]\n",
    "\n",
    "# out.items()[\"out.items()\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "abab9bcb-002d-4010-8f1e-e5d0696e5897",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "the meaning of life is not to be understood as a \"life\" but as a \"life of the soul\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "prompt = \"the meaning of life \"\n",
    "inp = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "out = model(input_ids=inp[\"input_ids\"], attention_mask=inp[\"attention_mask\"])\n",
    "\n",
    "num_tokens_to_generate = 20\n",
    "logits = out.logits\n",
    "generated_token_ids = inp[\"input_ids\"].squeeze().tolist()\n",
    "\n",
    "for _ in range(num_tokens_to_generate):\n",
    "    print(_)\n",
    "    last_token_logits = logits[:, -1, :]\n",
    "    probs = F.softmax(last_token_logits, dim=-1)\n",
    "    next_token_id = torch.argmax(probs, dim=-1).item()\n",
    "\n",
    "    generated_token_ids.append(next_token_id)\n",
    "\n",
    "    inp[\"input_ids\"] = torch.tensor([generated_token_ids]).to(inp[\"input_ids\"].device)\n",
    "    inp[\"attention_mask\"] = torch.tensor(inp[\"attention_mask\"].flatten().tolist() + [1]).view(1, -1)\n",
    "    out = model(input_ids=inp[\"input_ids\"], attention_mask=inp[\"attention_mask\"])\n",
    "    logits = out.logits\n",
    "\n",
    "generated_text = tokenizer.decode(generated_token_ids, skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "74bac8c4-ccaa-4e01-bd3c-9251ce76ba81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the meaning of life is not to be understood as a \"life\" but as a \"life of the soul\"\n"
     ]
    }
   ],
   "source": [
    "generated_text = tokenizer.decode(generated_token_ids, skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "515fcdf6-dc02-486a-868e-9dd7c36ff155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(\"up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf5f29-6cfc-4e98-9744-869dad075c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": rm.decision.parameters(), \"lr\": 5e-4},\n",
    "    {\"params\": rm.enc_model.parameters(), \"lr\": 5e-5},\n",
    "], lr=5e-5)\n",
    "\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "lr_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    rm.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_id, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out, label = rm(batch)\n",
    "        loss = - (out * label).sum() / label.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_id % 50 == 0:\n",
    "            print(loss.item())\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Average Training Loss: {avg_loss:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
