{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d120bc7-8d79-4df7-ac08-8af370c0e6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import dill\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification, AutoModel, GPT2Tokenizer\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# from dataset import TextDataset, clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afaccf4f-072d-44ed-a53e-821647098dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_og = pd.read_parquet(\"cspref/data/train-00000-of-00001.parquet\")\n",
    "\n",
    "# little bit of cleaning\n",
    "for col in ['sent_1', 'sent_2']:\n",
    "    df_og[col] = df_og[col].apply(lambda x:  x.split('\\n')[0] if '\\n' in x else x)\n",
    "\n",
    "df = df_og.sample(n=int(df_og.shape[0] * 0.6), random_state=42)\n",
    "\n",
    "chosen_class = {\n",
    "    \"sent_1\": 0,\n",
    "    \"sent_2\": 1,\n",
    "    \"tie\": 2\n",
    "}\n",
    "\n",
    "df[\"chosen\"] = df[\"chosen\"].apply(lambda x: chosen_class[x])\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenized_data = []\n",
    "        self.label_dict = {\n",
    "            0: torch.tensor([1, 0, 0]),\n",
    "            1: torch.tensor([0, 1, 0]),\n",
    "            2: torch.tensor([0, 0, 1])\n",
    "        }\n",
    "\n",
    "        kwargs = {\n",
    "            # \"add_special_tokens\": True,\n",
    "            \"padding\": \"max_length\",\n",
    "            \"truncation\": True,\n",
    "            \"return_attention_mask\": True,\n",
    "            \"return_tensors\": \"pt\"\n",
    "        }\n",
    "\n",
    "        for idx in range(len(df)):\n",
    "            prepend = (\n",
    "                df.iloc[idx][\"original_l1\"]\n",
    "                + \"+\"\n",
    "                + df.iloc[idx][\"original_l2\"]\n",
    "                + \"->\"\n",
    "            )\n",
    "            text1 = prepend + df.iloc[idx][\"sent_1\"]\n",
    "            text2 = prepend + df.iloc[idx][\"sent_2\"]\n",
    "            text1_enc = self.tokenizer.encode_plus(text1, **kwargs)\n",
    "            text2_enc = self.tokenizer.encode_plus(text2, **kwargs)\n",
    "\n",
    "            chosen = df.iloc[idx][\"chosen\"]\n",
    "            label = self.label_dict[chosen]\n",
    "\n",
    "            self.tokenized_data.append((text1_enc, text2_enc, chosen, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.tokenized_data[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e869aef2-bea6-4707-b589-5066062e2b78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not anymore\n"
     ]
    }
   ],
   "source": [
    "class DecisionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecisionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(768, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.reward_to_class = nn.Linear(2, 3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        r1 = self.fc2(F.gelu(self.fc1(x1)))\n",
    "        r2 = self.fc2(F.gelu(self.fc1(x2)))\n",
    "        \n",
    "        out = F.relu(torch.concat((r1, r2), dim=1))\n",
    "        out = self.reward_to_class(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, enc_model, decision, device):\n",
    "        super(RewardModel, self).__init__()\n",
    "        self.enc_model = enc_model\n",
    "        self.decision = decision\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [x1, x2, label]\n",
    "        input_ids = x[0]['input_ids'].squeeze(dim=1).to(self.device)\n",
    "        attention_mask = x[0]['attention_mask'].squeeze(dim=1).to(self.device)\n",
    "        out1 = self.enc_model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        out1 = out1.hidden_states[-1][:, -1, :]\n",
    "\n",
    "        input_ids = x[1]['input_ids'].squeeze(dim=1).to(self.device)\n",
    "        attention_mask = x[1]['attention_mask'].squeeze(dim=1).to(self.device)\n",
    "        out2 = self.enc_model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        out2 = out2.hidden_states[-1][:, -1, :]\n",
    "\n",
    "        output = self.decision(out1, out2)\n",
    "        label = x[-1].to(self.device)\n",
    "\n",
    "        return output, label\n",
    "\n",
    "    \n",
    "MODEL = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "enc_model = AutoModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "dm = DecisionModel()\n",
    "rm = RewardModel(enc_model, dm, device)\n",
    "rm.to(device)\n",
    "\n",
    "print(\"Not anymore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d127dc0-05f2-4ef7-bdd1-80e345944d97",
   "metadata": {},
   "source": [
    "### Test Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "338b2c3f-004b-46d4-9262-c41126dc3553",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7514, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "test_dataset = TextDataset(test_df, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=6, shuffle=True)\n",
    "\n",
    "test_dataloader.dataset.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4dc7045-4fb4-4173-b64f-3dc6323af6b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rm.load_state_dict(torch.load(\"models_w_tie/gpt2_rm_w_tie_40_4.pth\"))\n",
    "checkpoint = torch.load(\"ckpts_nl/checkpoint_gpt2_60_5.pth\")\n",
    "rm.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "rm.eval()\n",
    "\n",
    "all_preds = []\n",
    "true_labels = []\n",
    "chosen = []\n",
    "pred_model_probs = []\n",
    "\n",
    "for batch_id, batch in enumerate(test_dataloader):\n",
    "    chosen += batch[2].tolist()\n",
    "    out, label = rm(batch)\n",
    "    probs = F.softmax(out, dim=1)\n",
    "    pred_model_probs += probs.to(\"cpu\").tolist()\n",
    "    all_preds += probs.argmax(dim=1)\n",
    "    true_labels += label.argmax(dim=1).to(\"cpu\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a0cd08-8228-414f-952e-0d176c1de0c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5474)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(all_preds) == torch.tensor(true_labels)).sum() / len(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01688103-54ba-44f8-b69a-4de409ed1386",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ecfbf18-6442-48ca-a8d1-e2037eb7b309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af565a47-7ce8-447b-9509-76ac914aef2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_df.sample(frac=0.25), tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400c7506-8194-4f37-b759-38c590e01888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5869)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"ckpts_nl/checkpoint_gpt2_60_5.pth\")\n",
    "rm.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "all_preds = []\n",
    "true_labels = []\n",
    "chosen = []\n",
    "pred_model_probs = []\n",
    "\n",
    "for batch_id, batch in enumerate(train_dataloader):\n",
    "    chosen += batch[2].tolist()\n",
    "    out, label = rm(batch)\n",
    "    probs = F.softmax(out, dim=1)\n",
    "    pred_model_probs += probs.to(\"cpu\").tolist()\n",
    "    all_preds += probs.argmax(dim=1)\n",
    "    true_labels += label.argmax(dim=1).to(\"cpu\").tolist()\n",
    "\n",
    "    if batch_id == 300:\n",
    "        break\n",
    "\n",
    "(torch.tensor(all_preds) == torch.tensor(true_labels)).sum() / len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0344f753-3095-4aa6-bab1-bb89a8ecbdb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
