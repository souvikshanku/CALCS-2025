{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1edd34fe-4f81-42bd-8254-ef72b0e87558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from dataset import TextDataset\n",
    "from model import DecisionModel, RewardModel\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7d0bf8-a34b-4574-92ec-62a3df64afec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/calcs_test_split.csv\")\n",
    "chosen_class = {\n",
    "    \"sent_1\": 0,\n",
    "    \"sent_2\": 1,\n",
    "    \"tie\": 2\n",
    "}\n",
    "df_test[\"chosen\"] = df_test[\"chosen\"].apply(lambda x: chosen_class[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b58ea62-51db-462a-91e4-7d9b4372e546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RewardModel(\n",
       "  (enc_model): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decision): DecisionModel(\n",
       "    (fc1): Linear(in_features=768, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "enc_model = AutoModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "dm = DecisionModel()\n",
    "rm = RewardModel(enc_model, dm, device)\n",
    "rm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54041815-7474-4dcb-9945-a4ef5d8b46ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "test_dataset = TextDataset(df_test, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "233cb0d7-284b-447d-8126-8bf03d9527a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"ckpt/gpt2_rm_epoch5.pth\")\n",
    "\n",
    "rm.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "rm.eval()\n",
    "\n",
    "all_preds = []\n",
    "chosen = []\n",
    "pred_model_probs = []\n",
    "\n",
    "for batch_id, batch in enumerate(test_dataloader):\n",
    "    chosen += batch[2].tolist()\n",
    "    out, label = rm(batch)\n",
    "    probs = F.softmax(out, dim=1)\n",
    "\n",
    "    pred_model_probs += probs.to(\"cpu\").tolist()\n",
    "    all_preds += probs.argmax(dim=1)\n",
    "\n",
    "all_preds = [tensor.item() for tensor in all_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c4d90c-e6f7-4865-8138-08ab7aeb09c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1: 52.337753851574575\n",
      "Accuracy: 0.5281045751633987\n"
     ]
    }
   ],
   "source": [
    "diffs = np.arange(0, 1, 0.05)\n",
    "f1s = []\n",
    "\n",
    "for diff in diffs:\n",
    "    custom_preds = [\n",
    "        2 if np.abs(pred_model_probs[i][1] - pred_model_probs[i][0]) <= diff\n",
    "        else np.argmax(pred_model_probs[i])\n",
    "        for i in range(len(pred_model_probs))\n",
    "    ]\n",
    "\n",
    "    f1 = f1_score(chosen,custom_preds, average='macro')\n",
    "    f1s.append(f1)\n",
    "    \n",
    "    \n",
    "best_diff = diffs[f1s.index(max(f1s))]\n",
    "print(\"Best f1:\", max(f1s) * 100)\n",
    "\n",
    "custom_preds = [\n",
    "    2 if np.abs(pred_model_probs[i][1] - pred_model_probs[i][0]) <= best_diff\n",
    "    else np.argmax(pred_model_probs[i])\n",
    "    for i in range(len(pred_model_probs))\n",
    "]\n",
    "\n",
    "\n",
    "acc = [i == j for i, j in zip(custom_preds, chosen)]\n",
    "print(\"Accuracy:\", sum(acc)/ len(custom_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
